{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f3c814",
   "metadata": {},
   "source": [
    "# 02 - Feature Engineering\n",
    "## Pre-Scorer Features, TF-IDF, and Money Extraction\n",
    "\n",
    "Deterministic features computed before LLM scoring. Zero cost, runs locally.\n",
    "\n",
    "**Data source:** Parameterized via `AWESOMEBITS_DB` env var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb527170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from price_parser import Price\n",
    "import re\n",
    "\n",
    "setup_plotting()\n",
    "con = connect()\n",
    "df = con.execute('SELECT * FROM projects').df()\n",
    "df['label'] = df.apply(label_project, axis=1)\n",
    "df['text'] = df.apply(combined_text, axis=1)\n",
    "print(f'Loaded {len(df):,} applications')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def555a",
   "metadata": {},
   "source": [
    "## Pre-Scorer Feature Replication\n",
    "\n",
    "Replicate the Ruby `PreScorer` features in Python for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59deda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(row):\n",
    "    \"\"\"Replicate Ruby PreScorer features.\"\"\"\n",
    "    features = {}\n",
    "    texts = {f: str(row.get(f, '') or '') for f in TEXT_FIELDS}\n",
    "    all_text = ' '.join(t.strip() for t in texts.values() if t.strip())\n",
    "\n",
    "    # Word counts\n",
    "    for f in TEXT_FIELDS:\n",
    "        features[f'wc_{f}'] = word_count(texts[f])\n",
    "    features['wc_total'] = sum(features[f'wc_{f}'] for f in TEXT_FIELDS)\n",
    "\n",
    "    # Field length variance\n",
    "    counts = [features[f'wc_{f}'] for f in TEXT_FIELDS]\n",
    "    mean = np.mean(counts)\n",
    "    features['field_length_variance'] = np.var(counts)\n",
    "\n",
    "    # Sentence stats\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', all_text) if s.strip()]\n",
    "    sent_lens = [len(s.split()) for s in sentences]\n",
    "    features['sentence_count'] = len(sentences)\n",
    "    features['avg_sentence_length'] = np.mean(sent_lens) if sent_lens else 0\n",
    "    features['sentence_length_variance'] = np.var(sent_lens) if sent_lens else 0\n",
    "\n",
    "    # Punctuation\n",
    "    features['exclamation_count'] = all_text.count('!')\n",
    "    features['question_mark_count'] = all_text.count('?')\n",
    "\n",
    "    # Content signals\n",
    "    features['url_count'] = len(re.findall(r'https?://\\S+', all_text))\n",
    "    features['money_mention_count'] = money_mention_count(all_text)\n",
    "    features['number_count'] = len(re.findall(r'\\b\\d[\\d,.]*\\b', all_text))\n",
    "    features['email_count'] = len(re.findall(r'\\S+@\\S+\\.\\S+', all_text))\n",
    "\n",
    "    # Empty fields\n",
    "    features['empty_field_count'] = sum(1 for f in TEXT_FIELDS if not texts[f].strip())\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "# Compute for all projects\n",
    "print('Computing pre-scorer features...')\n",
    "feat_df = df.apply(compute_features, axis=1)\n",
    "df = pd.concat([df, feat_df], axis=1)\n",
    "print(f'Features computed: {list(feat_df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e513c",
   "metadata": {},
   "source": [
    "## Feature Distributions: Funded vs Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6797c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature distributions\n",
    "labeled = df[df.label.isin(['funded', 'hidden'])].copy()\n",
    "feature_cols = [c for c in feat_df.columns if c != 'empty_field_count']\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "for ax, col in zip(axes.flat, feature_cols):\n",
    "    for label, color in [('funded', 'mediumseagreen'), ('hidden', 'salmon')]:\n",
    "        data = labeled[labeled.label == label][col]\n",
    "        q99 = data.quantile(0.99)\n",
    "        ax.hist(data[data <= q99], bins=30, alpha=0.6, color=color, label=label, density=True)\n",
    "    ax.set_title(col, fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "for ax in axes.flat[len(feature_cols):]:\n",
    "    ax.set_visible(False)\n",
    "plt.suptitle('Feature Distributions: Funded vs Hidden', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature means by label\n",
    "summary = df.groupby('label')[feature_cols].mean().round(2).T\n",
    "summary['funded_hidden_ratio'] = (summary['funded'] / summary['hidden'].replace(0, np.nan)).round(2)\n",
    "print(summary[['funded', 'hidden', 'unlabeled', 'funded_hidden_ratio']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78117e43",
   "metadata": {},
   "source": [
    "## Money Extraction Analysis\n",
    "\n",
    "Using regex pattern matching to find currency mentions across the full corpus. This feeds the `money_mention_count` pre-scorer feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Money mention distribution\n",
    "print('Money mention counts by label:')\n",
    "for label in ['funded', 'hidden', 'unlabeled']:\n",
    "    subset = df[df.label == label]\n",
    "    mc = subset.money_mention_count\n",
    "    print(f'  {label:>10}: mean={mc.mean():.2f}, median={mc.median():.0f}, '\n",
    "          f'zero={((mc == 0).mean()):.1%}, 3+={((mc >= 3).mean()):.1%}')\n",
    "\n",
    "# Show examples of extracted money mentions\n",
    "print('\\nSample money extractions (funded apps):')\n",
    "funded_with_money = df[(df.label == 'funded') & (df.money_mention_count > 0)].sample(5, random_state=42)\n",
    "for _, row in funded_with_money.iterrows():\n",
    "    mentions = extract_money_mentions(row.text)\n",
    "    print(f'  [{row.money_mention_count} mentions] {mentions[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f5869",
   "metadata": {},
   "source": [
    "## TF-IDF Analysis\n",
    "\n",
    "Compute corpus-wide IDF values to identify distinctive vocabulary in funded vs hidden applications. The static IDF table can be exported for use in the Ruby pre-scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c73c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TF-IDF on full corpus\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    stop_words='english',\n",
    "    min_df=10,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "tfidf_matrix = tfidf.fit_transform(df.text.fillna(''))\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "idf_values = tfidf.idf_\n",
    "\n",
    "print(f'Vocabulary size: {len(feature_names):,}')\n",
    "print(f'IDF range: {idf_values.min():.2f} to {idf_values.max():.2f}')\n",
    "\n",
    "# Most and least common terms\n",
    "idf_df = pd.DataFrame({'term': feature_names, 'idf': idf_values}).sort_values('idf')\n",
    "print('\\nMost common terms (lowest IDF):')\n",
    "print(idf_df.head(20).to_string(index=False))\n",
    "print('\\nRarest terms (highest IDF):')\n",
    "print(idf_df.tail(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terms most distinctive of funded vs hidden\n",
    "funded_mask = (df.label == 'funded').values\n",
    "hidden_mask = (df.label == 'hidden').values\n",
    "\n",
    "funded_mean = np.asarray(tfidf_matrix[funded_mask].mean(axis=0)).flatten()\n",
    "hidden_mean = np.asarray(tfidf_matrix[hidden_mask].mean(axis=0)).flatten()\n",
    "\n",
    "diff = funded_mean - hidden_mean\n",
    "diff_df = pd.DataFrame({'term': feature_names, 'funded_mean': funded_mean, 'hidden_mean': hidden_mean, 'diff': diff})\n",
    "diff_df = diff_df.sort_values('diff', ascending=False)\n",
    "\n",
    "print('Terms most associated with FUNDED:')\n",
    "print(diff_df.head(25)[['term', 'funded_mean', 'hidden_mean', 'diff']].to_string(index=False))\n",
    "print('\\nTerms most associated with HIDDEN:')\n",
    "print(diff_df.tail(25)[['term', 'funded_mean', 'hidden_mean', 'diff']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top distinctive terms\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "top_funded = diff_df.head(20)\n",
    "ax1.barh(top_funded.term, top_funded['diff'], color='mediumseagreen')\n",
    "ax1.set_title('Top 20 Terms: Funded')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "top_hidden = diff_df.tail(20).iloc[::-1]\n",
    "ax2.barh(top_hidden.term, top_hidden['diff'].abs(), color='salmon')\n",
    "ax2.set_title('Top 20 Terms: Hidden')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.suptitle('TF-IDF: Most Distinctive Terms by Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ed730",
   "metadata": {},
   "source": [
    "## Export Static IDF Table\n",
    "\n",
    "Export the IDF values as JSON for use in the Ruby pre-scorer. This avoids recomputing TF-IDF at scoring time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0637f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "idf_export = dict(zip(feature_names.tolist(), idf_values.round(4).tolist()))\n",
    "\n",
    "out_path = Path(DB_PATH).parent / 'idf_table.json'\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(idf_export, f)\n",
    "print(f'Exported {len(idf_export):,} IDF values to {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47052ed5",
   "metadata": {},
   "source": [
    "## Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21de230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of pre-scorer features\n",
    "corr = df[feature_cols].corr()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0, ax=ax)\n",
    "ax.set_title('Pre-Scorer Feature Correlations')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
