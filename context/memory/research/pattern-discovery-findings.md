# Pattern Discovery Findings

## Method

3 independent batches of 40 labeled Chicago applications analyzed via Claude Sonnet for qualitative patterns. Cross-batch synthesis to identify stable signals.

## Stable Signals (consistent across all 3 batches)

1. **Money destination is #1 discriminator** — Materials/supplies = funded. Self-payment/living expenses = hidden. If >50% budget goes to applicant → almost always hidden.

2. **Local specificity signals authenticity** — Funded apps mention specific streets, organizations, aldermen. Hidden apps are geographically vague.

3. **Writing quality barely matters** — Quirky, unpolished but authentic applications outperform polished corporate ones.

4. **Scale fit is critical** — Projects perfectly sized for $1K succeed. "Drop in the bucket" requests get filtered.

5. **Community connector density** — Funded apps average 3-5 named local partnerships. Hidden apps have 0-1.

6. **Professional credentials hurt** — Academic degrees, awards, institutional affiliations correlate with HIDDEN status.

## Additional Signals from Video Archive Analysis (39 videos, 4 analysis groups)

### 4/4 Consensus (universal across all groups)
- **Catalytic Potential** — Does $1K unlock something bigger?
- **Creativity/Surprise** — Core AF identity, not a nice-to-have

### 3/4 Consensus
- **Funding Orphan Score** — Too weird/small for traditional funders = more awesome
- **Agency Framing** — "I will build" vs. "please help us"

### 2/4 Consensus
- **Boring Detection** — Not spam, just generic and uninspired
- **Validation Hunger** — First-time applicants where AF's belief matters most
- **Community Creation** — Builds new connections, not just serves existing

## Calibration
Multiple chapters independently report ~28% of applications are review-worthy regardless of volume.
